{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "# CrewAI Agent with GitHub MCP Server\n",
    "\n",
    "This notebook demonstrates how to build a **CrewAI** agent that connects to the\n",
    "[GitHub MCP Server](https://github.com/modelcontextprotocol/servers/tree/main/src/github)\n",
    "using the Model Context Protocol (MCP). The agent uses a locally-hosted\n",
    "**LLaMA 3.2** model via Ollama to reason and act on GitHub data.\n",
    "\n",
    "---\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────┐\n",
    "│                      CrewAI Crew                    │\n",
    "│                                                     │\n",
    "│  ┌──────────────────────────────────────────────┐   │\n",
    "│  │           GitHub Repository Analyst          │   │\n",
    "│  │   LLM: Ollama / LLaMA 3.2 (lambda2.uncw.edu) │   │\n",
    "│  │   Tools: GitHub MCP Server (via npx)         │   │\n",
    "│  └──────────────────────────────────────────────┘   │\n",
    "└─────────────────────────────────────────────────────┘\n",
    "                          │\n",
    "          MCP Stdio Transport (subprocess)\n",
    "                          │\n",
    "          @modelcontextprotocol/server-github\n",
    "                          │\n",
    "                   GitHub REST API\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Run the installation cell below, then set your GitHub Personal Access Token\n",
    "as an environment variable before proceeding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c3d4e5",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies\n",
    "\n",
    "Install the required Python packages and the GitHub MCP server (Node.js package).\n",
    "\n",
    "> **Note:** The `npx` command below will auto-install `@modelcontextprotocol/server-github`\n",
    "> on first use. You still need Node.js / npm available on your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d4e5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Python dependencies\n",
    "%pip install --quiet crewai crewai-tools mcp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e5f6a7",
   "metadata": {},
   "source": [
    "## 2. Set GitHub Token\n",
    "\n",
    "The GitHub MCP server needs a Personal Access Token (PAT) to authenticate with\n",
    "the GitHub API. Create one at https://github.com/settings/tokens with at least\n",
    "**repo** (read) scope.\n",
    "\n",
    "Set it as an environment variable — **never hard-code tokens in notebooks**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6a7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Option A: already set in your shell environment\n",
    "# export GITHUB_PERSONAL_ACCESS_TOKEN=ghp_...\n",
    "\n",
    "# Option B: set it here (use getpass so the token isn't visible)\n",
    "import getpass\n",
    "\n",
    "if not os.environ.get(\"GITHUB_PERSONAL_ACCESS_TOKEN\"):\n",
    "    os.environ[\"GITHUB_PERSONAL_ACCESS_TOKEN\"] = getpass.getpass(\n",
    "        \"Enter your GitHub Personal Access Token: \"\n",
    "    )\n",
    "\n",
    "github_token = os.environ[\"GITHUB_PERSONAL_ACCESS_TOKEN\"]\n",
    "print(\"Token loaded:\", \"✅\" if github_token else \"❌ not set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a7b8c9",
   "metadata": {},
   "source": [
    "## 3. Import Libraries\n",
    "\n",
    "| Import | Purpose |\n",
    "|---|---|\n",
    "| `crewai.LLM` | Wrapper around LLM backends (Ollama, OpenAI, etc.) |\n",
    "| `crewai.Agent` | Defines a role-playing AI agent with goals and tools |\n",
    "| `crewai.Task` | A unit of work assigned to an agent |\n",
    "| `crewai.Crew` | Orchestrates agents and tasks |\n",
    "| `crewai_tools.MCPServerAdapter` | Bridges MCP servers into CrewAI tools |\n",
    "| `mcp.StdioServerParameters` | Config for launching an MCP server as a subprocess |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b8c9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew, LLM\n",
    "from crewai_tools import MCPServerAdapter\n",
    "from mcp import StdioServerParameters\n",
    "\n",
    "print(\"Imports successful ✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c9d0e1",
   "metadata": {},
   "source": [
    "## 4. Configure the LLM\n",
    "\n",
    "We use a locally-hosted **LLaMA 3.2** model served via\n",
    "[Ollama](https://ollama.ai/) on `lambda2.uncw.edu`.\n",
    "\n",
    "The `LLM` class from CrewAI accepts any LiteLLM-compatible model string, so\n",
    "swapping to a different provider (OpenAI, Anthropic, etc.) is a one-line change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d0e1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LLM(\n",
    "    model=\"ollama/llama3.2\",\n",
    "    base_url=\"http://lambda2.uncw.edu:11434/api/generate\",\n",
    ")\n",
    "\n",
    "print(f\"LLM configured: {llm.model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e1f2a3",
   "metadata": {},
   "source": [
    "## 5. Configure the GitHub MCP Server\n",
    "\n",
    "`StdioServerParameters` tells the `MCPServerAdapter` how to launch the MCP\n",
    "server as a subprocess:\n",
    "\n",
    "- **`command`** — the executable to run (`npx`)\n",
    "- **`args`** — arguments passed to `npx`; `-y` auto-confirms the install\n",
    "- **`env`** — environment variables forwarded to the subprocess (our token)\n",
    "\n",
    "The adapter will start the process, perform the MCP handshake, and expose all\n",
    "server-advertised tools as standard CrewAI tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f2a3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_params = StdioServerParameters(\n",
    "    command=\"npx\",\n",
    "    args=[\"-y\", \"@modelcontextprotocol/server-github\"],\n",
    "    env={\"GITHUB_PERSONAL_ACCESS_TOKEN\": github_token},\n",
    ")\n",
    "\n",
    "print(\"MCP server parameters configured ✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a3b4c5",
   "metadata": {},
   "source": [
    "## 6. Define the Agent\n",
    "\n",
    "A CrewAI **Agent** has three key attributes that shape its behaviour:\n",
    "\n",
    "| Attribute | Description |\n",
    "|---|---|\n",
    "| `role` | The agent's job title — used in prompts and logs |\n",
    "| `goal` | What the agent is trying to achieve |\n",
    "| `backstory` | Persona / context that influences reasoning style |\n",
    "\n",
    "The agent is given the full list of GitHub MCP tools so it can call whichever\n",
    "ones it needs to complete its task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b4c5d6",
   "metadata": {},
   "source": [
    "## 7. Define the Task\n",
    "\n",
    "A **Task** is a concrete assignment given to an agent. Two fields matter most:\n",
    "\n",
    "- **`description`** — natural-language instructions for what to do\n",
    "- **`expected_output`** — tells the agent (and the Crew) what a successful\n",
    "  result looks like, used for self-evaluation and hand-off\n",
    "\n",
    "Feel free to change the description to explore any public GitHub repository!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c5d6e7",
   "metadata": {},
   "source": [
    "## 8. Assemble and Run the Crew\n",
    "\n",
    "Everything runs inside the `MCPServerAdapter` context manager, which:\n",
    "\n",
    "1. Spawns the `npx` subprocess\n",
    "2. Performs the MCP protocol handshake\n",
    "3. Yields the list of available tools\n",
    "4. Cleans up the subprocess on exit\n",
    "\n",
    "`crew.kickoff()` starts the agentic loop — the agent will reason, call GitHub\n",
    "tools, observe results, and iterate until it produces a final answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d6e7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with MCPServerAdapter(server_params) as github_tools:\n",
    "\n",
    "    # ── Inspect available tools ────────────────────────────────────────────\n",
    "    print(\"Available GitHub MCP tools:\")\n",
    "    for tool in github_tools:\n",
    "        print(f\"  • {tool.name}\")\n",
    "\n",
    "    # ── Agent ──────────────────────────────────────────────────────────────\n",
    "    github_agent = Agent(\n",
    "        role=\"GitHub Repository Analyst\",\n",
    "        goal=(\n",
    "            \"Retrieve and analyse information from GitHub repositories \"\n",
    "            \"to answer the user's question accurately.\"\n",
    "        ),\n",
    "        backstory=(\n",
    "            \"You are an expert software engineer who specialises in \"\n",
    "            \"exploring GitHub repositories, reading issues, pull requests, \"\n",
    "            \"and code to provide clear, concise summaries and insights.\"\n",
    "        ),\n",
    "        tools=github_tools,\n",
    "        llm=llm,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    # ── Task ───────────────────────────────────────────────────────────────\n",
    "    research_task = Task(\n",
    "        description=(\n",
    "            \"Search GitHub for the repository 'anthropics/anthropic-sdk-python'. \"\n",
    "            \"Retrieve the repository details (description, stars, open issues) \"\n",
    "            \"and list the 5 most recent open issues with their titles and URLs.\"\n",
    "        ),\n",
    "        expected_output=(\n",
    "            \"A structured summary containing:\\n\"\n",
    "            \"1. Repository description and key stats (stars, forks, open issues).\\n\"\n",
    "            \"2. A numbered list of the 5 most recent open issues with title and URL.\"\n",
    "        ),\n",
    "        agent=github_agent,\n",
    "    )\n",
    "\n",
    "    # ── Crew ───────────────────────────────────────────────────────────────\n",
    "    crew = Crew(\n",
    "        agents=[github_agent],\n",
    "        tasks=[research_task],\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    # ── Run ────────────────────────────────────────────────────────────────\n",
    "    result = crew.kickoff()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e7f8a9",
   "metadata": {},
   "source": [
    "## 9. Display the Final Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f8a9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"CREW RESULT\")\n",
    "print(\"=\" * 60)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a9b0c1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- **Change the task** — update the `description` in the Task cell to query any\n",
    "  other public repository or ask a different question.\n",
    "- **Add more agents** — create specialist agents (e.g. a Code Reviewer, a\n",
    "  Release Note Writer) and wire them together in the Crew.\n",
    "- **Swap the LLM** — replace `ollama/llama3.2` with `openai/gpt-4o` or any\n",
    "  other LiteLLM-supported model string.\n",
    "- **Explore other MCP servers** — the same pattern works with any MCP-compatible\n",
    "  server (filesystem, Slack, databases, etc.)."
   ]
  }
 ]
}
